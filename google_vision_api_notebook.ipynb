{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "google-vision-api-notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuQmso3l_X_R"
      },
      "source": [
        "# Image to Text\n",
        "\n",
        "https://www.youtube.com/watch?v=xKvffLRSyPk&list=PL3JVwFmb_BnSLFyVThMfEavAEZYHBpWEd&index=1&ab_channel=JieJenn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5arIUzB73MA"
      },
      "source": [
        "!pip install google-cloud-vision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8KqJj897rhT"
      },
      "source": [
        "import os, io\n",
        "from google.cloud import vision\n",
        "from google.cloud.vision_v1 import types\n",
        "import pandas as pd\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRs1JHT47sIp"
      },
      "source": [
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'path-to-credentials-json-file'\n",
        "client = vision.ImageAnnotatorClient()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "860DNBQ59KrJ"
      },
      "source": [
        "\n",
        "image_path = 'path-to-image-file'\n",
        "\n",
        "with io.open(image_path, 'rb') as image_file:\n",
        "    content = image_file.read()\n",
        "\n",
        "# construct an iamge instance\n",
        "image = types.Image(content=content, language_code='ur-PK')\n",
        "\n",
        "\n",
        "# annotate Image Response\n",
        "response = client.text_detection(image=image)  # returns TextAnnotation\n",
        "df = pd.DataFrame(columns=['locale', 'description'])\n",
        "\n",
        "texts = response.text_annotations\n",
        "for text in texts:\n",
        "    df = df.append(\n",
        "        dict(\n",
        "            locale=text.locale,\n",
        "            description=text.description\n",
        "        ),\n",
        "        ignore_index=True\n",
        "    )\n",
        "\n",
        "print(df['description'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O86cwstppvIH"
      },
      "source": [
        "# Sound to text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MotfbBjLpz6p"
      },
      "source": [
        "!pip install google-cloud-speech"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANnvv0KKp3U1"
      },
      "source": [
        "import io\n",
        "import os\n",
        "from google.cloud import speech\n",
        "from google.cloud.speech_v1 import types"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn_-eDC8p6Xb"
      },
      "source": [
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'path-to-credentials-json-file'\n",
        "client = speech.SpeechClient()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2k8q1vvqDVD"
      },
      "source": [
        "file_path = 'path-to-audio-file'\n",
        "\n",
        "with io.open(file_path, 'rb') as audio_file:\n",
        "  content = audio_file.read()\n",
        "  audio = types.RecognitionAudio(content=content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TBCVZp8qFc9"
      },
      "source": [
        "# encoding = speech.RecognitionConfig.AudioEncoding.LINEAR16\n",
        "config = types.RecognitionConfig(\n",
        "    encoding = speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
        "    sample_rate_hertz=16000,\n",
        "    language_code='ur-PK',\n",
        "    enable_word_time_offsets = True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA1JiIZ1qIA9"
      },
      "source": [
        "def print_sentences(response):\n",
        "    for result in response.results:\n",
        "        best_alternative = result.alternatives[0]\n",
        "        transcript = best_alternative.transcript\n",
        "        confidence = best_alternative.confidence\n",
        "        print(\"-\" * 80)\n",
        "        print(f\"Transcript: {transcript}\")\n",
        "        print(f\"Confidence: {confidence:.0%}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMYRDLDGqJwG"
      },
      "source": [
        "response = client.recognize(config=config, audio=audio)\n",
        "print_sentences(response)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}